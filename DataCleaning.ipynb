{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import xlrd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "data_path = 'D:\\Study\\Thesis\\Data\\Arendeforteckning.csv'\n",
    "raw_data = pd.read_csv(data_path, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing work\n",
    "# distinguish with the comma separation and comma within quote\n",
    "i = 2\n",
    "for i in range(len(raw_data.index)):\n",
    "    raw_data['Textbox3'][i] = re.sub(r'\"[^\"]*\"', lambda m: m.group(0).replace(',', ''), raw_data['Textbox3'][i])\n",
    "    i += 1\n",
    "\n",
    "#Seperated one column to different attribute, data re-columns based on comma\n",
    "data = raw_data[raw_data.columns[0]].str.split(',', expand = True)\n",
    "columns_name = data.iloc[1]\n",
    "data.columns = columns_name\n",
    "\n",
    "#Delete first two columns\n",
    "data = data.drop(data.index[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data-cleaning-drop null\n",
    "data = data.drop(data.index[(data[data.columns[0]] == '')|(data[data.columns[3]] == '')])\n",
    "data = data.dropna(axis = 1, how = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data re-columns\n",
    "Titles =       ['Contact_type',\n",
    "                'Complaint',\n",
    "                'Clinic',\n",
    "                'Content',\n",
    "                'Case_num',\n",
    "                'Contactor',\n",
    "                'Problem_Cat1',\n",
    "                'SubCat1',\n",
    "                'Case_status',\n",
    "                'Problem_Cat2',\n",
    "                'SubCat2',\n",
    "                'Problem_Cat3',\n",
    "                'Subcat3',\n",
    "                'Flag']\n",
    "\n",
    "data.columns = Titles\n",
    "\n",
    "data['Content'] = data['Content'].str.replace(\"\\\"\",\"\")\n",
    "\n",
    "#Re-index\n",
    "data = data.reset_index()\n",
    "data = data.drop(['index'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Candidate as the first iteration of sentiment analysis\n",
    "Candidate = data[['Content']].copy()\n",
    "\n",
    "#transpose all big letter to small letter\n",
    "Candidate['Content']= Candidate['Content'].str.lower()\n",
    "\n",
    "#Removing Punctuation\n",
    "Candidate['Content']= Candidate['Content'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "#Removal of commonly occurring words\n",
    "stop = nltk.corpus.stopwords.words('swedish')\n",
    "Candidate['remove']= Candidate['Content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common word removal\n",
    "freq = pd.Series(' '.join(Candidate['remove']).split()).value_counts()[:35]\n",
    "# DO not remove ['läkaren','läkare']\n",
    "not_remove=['läkaren','läkare']\n",
    "freq=freq.drop(labels=not_remove)\n",
    "#freq\n",
    "freq = list(freq.index)\n",
    "Candidate['remove'] = Candidate['remove'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rare words removal\n",
    "freq_rare = pd.Series(' '.join(Candidate['remove']).split()).value_counts()\n",
    "freq_rare = freq_rare[freq_rare == 1]\n",
    "\n",
    "freq_rare = list(freq_rare.index)\n",
    "Candidate['remove'] = Candidate['remove'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_rare))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokensize remove sentences\n",
    "Candidate['tokenize_sents'] = Candidate.apply(lambda row: nltk.word_tokenize(row['remove']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>remove</th>\n",
       "      <th>tokenize_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en kvinna föll och ådrog sig en skada i ena ax...</td>\n",
       "      <td>föll ådrog skada ena axeln fortfarande stora s...</td>\n",
       "      <td>[föll, ådrog, skada, ena, axeln, fortfarande, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en kvinna hade genomgått en operation och vård...</td>\n",
       "      <td>genomgått vårdades tillsammans andra patienter...</td>\n",
       "      <td>[genomgått, vårdades, tillsammans, andra, pati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en man med symtom från mag tarmkanalen sökte a...</td>\n",
       "      <td>symtom akutmottagning sjukhuset gånger rätt di...</td>\n",
       "      <td>[symtom, akutmottagning, sjukhuset, gånger, rä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en kvinna med bröstcancer har genomgått strålb...</td>\n",
       "      <td>genomgått ena bröstet behandlingen försökt kom...</td>\n",
       "      <td>[genomgått, ena, bröstet, behandlingen, försök...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en kvinna hade problem med trötthet och stort ...</td>\n",
       "      <td>problem stort genomgick undersökningar svar vi...</td>\n",
       "      <td>[problem, stort, genomgick, undersökningar, sv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  en kvinna föll och ådrog sig en skada i ena ax...   \n",
       "1  en kvinna hade genomgått en operation och vård...   \n",
       "2  en man med symtom från mag tarmkanalen sökte a...   \n",
       "3  en kvinna med bröstcancer har genomgått strålb...   \n",
       "4  en kvinna hade problem med trötthet och stort ...   \n",
       "\n",
       "                                              remove  \\\n",
       "0  föll ådrog skada ena axeln fortfarande stora s...   \n",
       "1  genomgått vårdades tillsammans andra patienter...   \n",
       "2  symtom akutmottagning sjukhuset gånger rätt di...   \n",
       "3  genomgått ena bröstet behandlingen försökt kom...   \n",
       "4  problem stort genomgick undersökningar svar vi...   \n",
       "\n",
       "                                      tokenize_sents  \n",
       "0  [föll, ådrog, skada, ena, axeln, fortfarande, ...  \n",
       "1  [genomgått, vårdades, tillsammans, andra, pati...  \n",
       "2  [symtom, akutmottagning, sjukhuset, gånger, rä...  \n",
       "3  [genomgått, ena, bröstet, behandlingen, försök...  \n",
       "4  [problem, stort, genomgick, undersökningar, sv...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Candidate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "writer = pd.ExcelWriter('CleanData1.xlsx')\n",
    "Candidate.to_excel(writer,'sheet1')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
